apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    cert-manager.io/inject-ca-from: aiven-operator-system/aiven-operator-serving-cert
    controller-gen.kubebuilder.io/version: v0.7.0
  creationTimestamp: null
  name: kafkas.aiven.io
spec:
  conversion:
    strategy: Webhook
    webhook:
      clientConfig:
        caBundle: Cg==
        service:
          name: webhook-service
          namespace: system
          path: /convert
          port: 443
      conversionReviewVersions:
      - v1
      - v1beta1
  group: aiven.io
  names:
    kind: Kafka
    listKind: KafkaList
    plural: kafkas
    singular: kafka
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - jsonPath: .spec.project
      name: Project
      type: string
    - jsonPath: .spec.cloudName
      name: Region
      type: string
    - jsonPath: .spec.plan
      name: Plan
      type: string
    - jsonPath: .status.state
      name: State
      type: string
    name: v1alpha1
    schema:
      openAPIV3Schema:
        description: Kafka is the Schema for the kafkas API
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: KafkaSpec defines the desired state of Kafka
            properties:
              authSecretRef:
                description: Authentication reference to Aiven token in a secret
                properties:
                  key:
                    minLength: 1
                    type: string
                  name:
                    minLength: 1
                    type: string
                required:
                - key
                - name
                type: object
              cloudName:
                description: Cloud the service runs in.
                maxLength: 256
                type: string
              connInfoSecretTarget:
                description: Information regarding secret creation
                properties:
                  name:
                    description: Name of the Secret resource to be created
                    type: string
                required:
                - name
                type: object
              maintenanceWindowDow:
                description: Day of week when maintenance operations should be performed.
                  One monday, tuesday, wednesday, etc.
                enum:
                - monday
                - tuesday
                - wednesday
                - thursday
                - friday
                - saturday
                - sunday
                - never
                type: string
              maintenanceWindowTime:
                description: Time of day when maintenance operations should be performed.
                  UTC time in HH:mm:ss format.
                maxLength: 8
                type: string
              plan:
                description: Subscription plan.
                maxLength: 128
                type: string
              project:
                description: Target project.
                format: ^[a-zA-Z0-9_-]*$
                maxLength: 63
                type: string
              projectVpcId:
                description: Identifier of the VPC the service should be in, if any.
                maxLength: 36
                type: string
              terminationProtection:
                description: Prevent service from being deleted. It is recommended
                  to have this enabled for all services.
                type: boolean
              userConfig:
                description: Kafka specific user configuration options
                properties:
                  ip_filter:
                    description: IP filter Allow incoming connections from CIDR address
                      block, e.g. '10.20.0.0/16'
                    items:
                      type: string
                    type: array
                  kafka:
                    description: Kafka broker configuration values
                    properties:
                      auto_create_topics_enable:
                        description: auto.create.topics.enable Enable auto creation
                          of topics
                        type: boolean
                      compression_type:
                        description: compression.type Specify the final compression
                          type for a given topic. This configuration accepts the standard
                          compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It
                          additionally accepts 'uncompressed' which is equivalent
                          to no compression; and 'producer' which means retain the
                          original compression codec set by the producer.
                        enum:
                        - gzip
                        - snappy
                        - lz4
                        - zstd
                        - uncompressed
                        - producer
                        type: string
                      connections_max_idle_ms:
                        description: 'connections.max.idle.ms Idle connections timeout:
                          the server socket processor threads close the connections
                          that idle for longer than this.'
                        format: int64
                        maximum: 3600000
                        minimum: 1000
                        type: integer
                      default_replication_factor:
                        description: default.replication.factor Replication factor
                          for autocreated topics
                        format: int64
                        maximum: 10
                        minimum: 1
                        type: integer
                      group_max_session_timeout_ms:
                        description: group.max.session.timeout.ms The maximum allowed
                          session timeout for registered consumers. Longer timeouts
                          give consumers more time to process messages in between
                          heartbeats at the cost of a longer time to detect failures.
                        format: int64
                        maximum: 1800000
                        minimum: 0
                        type: integer
                      group_min_session_timeout_ms:
                        description: group.min.session.timeout.ms The minimum allowed
                          session timeout for registered consumers. Longer timeouts
                          give consumers more time to process messages in between
                          heartbeats at the cost of a longer time to detect failures.
                        format: int64
                        maximum: 60000
                        minimum: 0
                        type: integer
                      log_cleaner_delete_retention_ms:
                        description: log.cleaner.delete.retention.ms How long are
                          delete records retained?
                        format: int64
                        maximum: 315569260000
                        minimum: 0
                        type: integer
                      log_cleaner_max_compaction_lag_ms:
                        description: log.cleaner.max.compaction.lag.ms The maximum
                          amount of time message will remain uncompacted. Only applicable
                          for logs that are being compacted
                        format: int64
                        minimum: 30000
                        type: integer
                      log_cleaner_min_cleanable_ratio:
                        description: log.cleaner.min.cleanable.ratio Controls log
                          compactor frequency. Larger value means more frequent compactions
                          but also more space wasted for logs. Consider setting log.cleaner.max.compaction.lag.ms
                          to enforce compactions sooner, instead of setting a very
                          high value for this option.
                        format: int64
                        maximum: 1
                        minimum: 0
                        type: integer
                      log_cleaner_min_compaction_lag_ms:
                        description: log.cleaner.min.compaction.lag.ms The minimum
                          time a message will remain uncompacted in the log. Only
                          applicable for logs that are being compacted.
                        format: int64
                        minimum: 0
                        type: integer
                      log_cleanup_policy:
                        description: log.cleanup.policy The default cleanup policy
                          for segments beyond the retention window
                        enum:
                        - compact
                        - delete
                        type: string
                      log_flush_interval_messages:
                        description: log.flush.interval.messages The number of messages
                          accumulated on a log partition before messages are flushed
                          to disk
                        format: int64
                        minimum: 1
                        type: integer
                      log_flush_interval_ms:
                        description: log.flush.interval.ms The maximum time in ms
                          that a message in any topic is kept in memory before flushed
                          to disk. If not set, the value in log.flush.scheduler.interval.ms
                          is used
                        format: int64
                        minimum: 0
                        type: integer
                      log_index_interval_bytes:
                        description: log.index.interval.bytes The interval with which
                          Kafka adds an entry to the offset index
                        format: int64
                        maximum: 104857600
                        minimum: 0
                        type: integer
                      log_index_size_max_bytes:
                        description: log.index.size.max.bytes The maximum size in
                          bytes of the offset index
                        format: int64
                        maximum: 104857600
                        minimum: 1048576
                        type: integer
                      log_message_downconversion_enable:
                        description: log.message.downconversion.enable This configuration
                          controls whether down-conversion of message formats is enabled
                          to satisfy consume requests.
                        type: boolean
                      log_message_timestamp_difference_max_ms:
                        description: log.message.timestamp.difference.max.ms The maximum
                          difference allowed between the timestamp when a broker receives
                          a message and the timestamp specified in the message
                        format: int64
                        minimum: 0
                        type: integer
                      log_message_timestamp_type:
                        description: log.message.timestamp.type Define whether the
                          timestamp in the message is message create time or log append
                          time.
                        enum:
                        - CreateTime
                        - LogAppendTime
                        type: string
                      log_preallocate:
                        description: log.preallocate Should pre allocate file when
                          create new segment?
                        type: boolean
                      log_retention_bytes:
                        description: log.retention.bytes The maximum size of the log
                          before deleting messages
                        format: int64
                        type: integer
                      log_retention_hours:
                        description: log.retention.hours The number of hours to keep
                          a log file before deleting it
                        format: int64
                        maximum: 2147483647
                        type: integer
                      log_retention_ms:
                        description: log.retention.ms The number of milliseconds to
                          keep a log file before deleting it (in milliseconds), If
                          not set, the value in log.retention.minutes is used. If
                          set to -1, no time limit is applied.
                        format: int64
                        type: integer
                      log_roll_jitter_ms:
                        description: log.roll.jitter.ms The maximum jitter to subtract
                          from logRollTimeMillis (in milliseconds). If not set, the
                          value in log.roll.jitter.hours is used
                        format: int64
                        minimum: 0
                        type: integer
                      log_roll_ms:
                        description: log.roll.ms The maximum time before a new log
                          segment is rolled out (in milliseconds).
                        format: int64
                        minimum: 1
                        type: integer
                      log_segment_bytes:
                        description: log.segment.bytes The maximum size of a single
                          log file
                        format: int64
                        maximum: 1073741824
                        minimum: 10485760
                        type: integer
                      log_segment_delete_delay_ms:
                        description: log.segment.delete.delay.ms The amount of time
                          to wait before deleting a file from the filesystem
                        format: int64
                        maximum: 3600000
                        minimum: 0
                        type: integer
                      max_connections_per_ip:
                        description: max.connections.per.ip The maximum number of
                          connections allowed from each ip address (defaults to 2147483647).
                        format: int64
                        maximum: 2147483647
                        minimum: 256
                        type: integer
                      max_incremental_fetch_session_cache_slots:
                        description: max.incremental.fetch.session.cache.slots The
                          maximum number of incremental fetch sessions that the broker
                          will maintain.
                        format: int64
                        maximum: 10000
                        minimum: 1000
                        type: integer
                      message_max_bytes:
                        description: message.max.bytes The maximum size of message
                          that the server can receive.
                        format: int64
                        maximum: 100001200
                        minimum: 0
                        type: integer
                      min_insync_replicas:
                        description: min.insync.replicas When a producer sets acks
                          to 'all' (or '-1'), min.insync.replicas specifies the minimum
                          number of replicas that must acknowledge a write for the
                          write to be considered successful.
                        format: int64
                        maximum: 7
                        minimum: 1
                        type: integer
                      num_partitions:
                        description: num.partitions Number of partitions for autocreated
                          topics
                        format: int64
                        maximum: 1000
                        minimum: 1
                        type: integer
                      offsets_retention_minutes:
                        description: offsets.retention.minutes Log retention window
                          in minutes for offsets topic
                        format: int64
                        maximum: 2147483647
                        minimum: 1
                        type: integer
                      producer_purgatory_purge_interval_requests:
                        description: producer.purgatory.purge.interval.requests The
                          purge interval (in number of requests) of the producer request
                          purgatory(defaults to 1000).
                        format: int64
                        maximum: 10000
                        minimum: 10
                        type: integer
                      replica_fetch_max_bytes:
                        description: replica.fetch.max.bytes The number of bytes of
                          messages to attempt to fetch for each partition (defaults
                          to 1048576). This is not an absolute maximum, if the first
                          record batch in the first non-empty partition of the fetch
                          is larger than this value, the record batch will still be
                          returned to ensure that progress can be made.
                        format: int64
                        maximum: 104857600
                        minimum: 1048576
                        type: integer
                      replica_fetch_response_max_bytes:
                        description: replica.fetch.response.max.bytes Maximum bytes
                          expected for the entire fetch response (defaults to 10485760).
                          Records are fetched in batches, and if the first record
                          batch in the first non-empty partition of the fetch is larger
                          than this value, the record batch will still be returned
                          to ensure that progress can be made. As such, this is not
                          an absolute maximum.
                        format: int64
                        maximum: 1048576000
                        minimum: 10485760
                        type: integer
                      socket_request_max_bytes:
                        description: socket.request.max.bytes The maximum number of
                          bytes in a socket request (defaults to 104857600).
                        format: int64
                        maximum: 209715200
                        minimum: 10485760
                        type: integer
                    type: object
                  kafka_authentication_methods:
                    description: Kafka authentication methods
                    properties:
                      certificate:
                        description: Enable certificate/SSL authentication
                        type: boolean
                      sasl:
                        description: Enable SASL authentication
                        type: boolean
                    type: object
                  kafka_connect:
                    description: Enable Kafka Connect service
                    type: boolean
                  kafka_connect_user_config:
                    description: Kafka Connect configuration values
                    properties:
                      connector_client_config_override_policy:
                        description: Client config override policy Defines what client
                          configurations can be overridden by the connector. Default
                          is None
                        enum:
                        - None
                        - All
                        type: string
                      consumer_auto_offset_reset:
                        description: Consumer auto offset reset What to do when there
                          is no initial offset in Kafka or if the current offset does
                          not exist any more on the server. Default is earliest
                        enum:
                        - earliest
                        - latest
                        type: string
                      consumer_fetch_max_bytes:
                        description: The maximum amount of data the server should
                          return for a fetch request Records are fetched in batches
                          by the consumer, and if the first record batch in the first
                          non-empty partition of the fetch is larger than this value,
                          the record batch will still be returned to ensure that the
                          consumer can make progress. As such, this is not a absolute
                          maximum.
                        format: int64
                        maximum: 104857600
                        minimum: 1048576
                        type: integer
                      consumer_isolation_level:
                        description: Consumer isolation level Transaction read isolation
                          level. read_uncommitted is the default, but read_committed
                          can be used if consume-exactly-once behavior is desired.
                        enum:
                        - read_uncommitted
                        - read_committed
                        type: string
                      consumer_max_partition_fetch_bytes:
                        description: The maximum amount of data per-partition the
                          server will return. Records are fetched in batches by the
                          consumer.If the first record batch in the first non-empty
                          partition of the fetch is larger than this limit, the batch
                          will still be returned to ensure that the consumer can make
                          progress.
                        format: int64
                        maximum: 104857600
                        minimum: 1048576
                        type: integer
                      consumer_max_poll_interval_ms:
                        description: The maximum delay between polls when using consumer
                          group management The maximum delay in milliseconds between
                          invocations of poll() when using consumer group management
                          (defaults to 300000).
                        format: int64
                        maximum: 2147483647
                        minimum: 1
                        type: integer
                      consumer_max_poll_records:
                        description: The maximum number of records returned by a single
                          poll The maximum number of records returned in a single
                          call to poll() (defaults to 500).
                        format: int64
                        maximum: 10000
                        minimum: 1
                        type: integer
                      offset_flush_interval_ms:
                        description: The interval at which to try committing offsets
                          for tasks The interval at which to try committing offsets
                          for tasks (defaults to 60000).
                        format: int64
                        maximum: 100000000
                        minimum: 1
                        type: integer
                      offset_flush_timeout_ms:
                        description: Offset flush timeout Maximum number of milliseconds
                          to wait for records to flush and partition offset data to
                          be committed to offset storage before cancelling the process
                          and restoring the offset data to be committed in a future
                          attempt (defaults to 5000).
                        format: int64
                        maximum: 2147483647
                        minimum: 1
                        type: integer
                      producer_max_request_size:
                        description: The maximum size of a request in bytes This setting
                          will limit the number of record batches the producer will
                          send in a single request to avoid sending huge requests.
                        format: int64
                        maximum: 10485760
                        minimum: 131072
                        type: integer
                      session_timeout_ms:
                        description: The timeout used to detect failures when using
                          Kafka’s group management facilities The timeout in milliseconds
                          used to detect failures when using Kafka’s group management
                          facilities (defaults to 10000).
                        format: int64
                        maximum: 2147483647
                        minimum: 1
                        type: integer
                    type: object
                  kafka_rest:
                    description: Enable Kafka-REST service
                    type: boolean
                  kafka_rest_config:
                    description: Kafka REST configuration
                    properties:
                      consumer_enable_auto_commit:
                        description: consumer.enable.auto.commit If true the consumer's
                          offset will be periodically committed to Kafka in the background
                        type: boolean
                      consumer_request_max_bytes:
                        description: consumer.request.max.bytes Maximum number of
                          bytes in unencoded message keys and values by a single request
                        format: int64
                        maximum: 671088640
                        minimum: 0
                        type: integer
                      consumer_request_timeout_ms:
                        description: consumer.request.timeout.ms The maximum total
                          time to wait for messages for a request if the maximum number
                          of messages has not yet been reached
                        enum:
                        - 1000
                        - 15000
                        - 30000
                        format: int64
                        maximum: 30000
                        minimum: 1000
                        type: integer
                      custom_domain:
                        description: Custom domain Serve the web frontend using a
                          custom CNAME pointing to the Aiven DNS name
                        maxLength: 255
                        type: string
                      producer_acks:
                        description: producer.acks The number of acknowledgments the
                          producer requires the leader to have received before considering
                          a request complete. If set to 'all' or '-1', the leader
                          will wait for the full set of in-sync replicas to acknowledge
                          the record.
                        enum:
                        - all
                        - -1
                        - 0
                        - 1
                        type: string
                      producer_linger_ms:
                        description: producer.linger.ms Wait for up to the given delay
                          to allow batching records together
                        format: int64
                        maximum: 5000
                        minimum: 0
                        type: integer
                      public_access:
                        description: Allow access to selected service ports from the
                          public Internet
                        properties:
                          kafka:
                            description: Allow clients to connect to kafka from the
                              public internet for service nodes that are in a project
                              VPC or another type of private network
                            type: boolean
                          kafka_connect:
                            description: Allow clients to connect to kafka_connect
                              from the public internet for service nodes that are
                              in a project VPC or another type of private network
                            type: boolean
                          kafka_rest:
                            description: Allow clients to connect to kafka_rest from
                              the public internet for service nodes that are in a
                              project VPC or another type of private network
                            type: boolean
                          prometheus:
                            description: Allow clients to connect to prometheus from
                              the public internet for service nodes that are in a
                              project VPC or another type of private network
                            type: boolean
                          schema_registry:
                            description: Allow clients to connect to schema_registry
                              from the public internet for service nodes that are
                              in a project VPC or another type of private network
                            type: boolean
                        type: object
                      simpleconsumer_pool_size_max:
                        description: simpleconsumer.pool.size.max Maximum number of
                          SimpleConsumers that can be instantiated per broker
                        format: int64
                        maximum: 250
                        minimum: 10
                        type: integer
                    type: object
                  kafka_version:
                    description: Kafka major version
                    enum:
                    - "1.0"
                    - "1.1"
                    - "2.0"
                    - "2.1"
                    - "2.2"
                    - "2.3"
                    - "2.4"
                    - "2.5"
                    - "2.6"
                    - "2.7"
                    - "2.8"
                    type: string
                  private_access:
                    description: Allow access to selected service ports from private
                      networks
                    properties:
                      prometheus:
                        description: Allow clients to connect to prometheus with a
                          DNS name that always resolves to the service's private IP
                          addresses. Only available in certain network locations
                        type: boolean
                    type: object
                  schema_registry:
                    description: Enable Schema-Registry service
                    type: boolean
                  schema_registry_config:
                    description: Schema Registry configuration
                    properties:
                      leader_eligibility:
                        description: leader_eligibility If true, Karapace / Schema
                          Registry on the service nodes can participate in leader
                          election. It might be needed to disable this when the schemas
                          topic is replicated to a secondary cluster and Karapace
                          / Schema Registry there must not participate in leader election.
                          Defaults to 'true'.
                        type: boolean
                      topic_name:
                        description: topic_name The durable single partition topic
                          that acts as the durable log for the data. This topic must
                          be compacted to avoid losing data due to retention policy.
                          Please note that changing this configuration in an existing
                          Schema Registry / Karapace setup leads to previous schemas
                          being inaccessible, data encoded with them potentially unreadable
                          and schema ID sequence put out of order. It's only possible
                          to do the switch while Schema Registry / Karapace is disabled.
                          Defaults to '_schemas'.
                        maxLength: 249
                        type: string
                    type: object
                type: object
            required:
            - authSecretRef
            - project
            type: object
          status:
            description: ServiceStatus defines the observed state of service
            properties:
              conditions:
                description: Conditions represent the latest available observations
                  of a service state
                items:
                  description: "Condition contains details for one aspect of the current
                    state of this API Resource. --- This struct is intended for direct
                    use as an array at the field path .status.conditions.  For example,
                    type FooStatus struct{     // Represents the observations of a
                    foo's current state.     // Known .status.conditions.type are:
                    \"Available\", \"Progressing\", and \"Degraded\"     // +patchMergeKey=type
                    \    // +patchStrategy=merge     // +listType=map     // +listMapKey=type
                    \    Conditions []metav1.Condition `json:\"conditions,omitempty\"
                    patchStrategy:\"merge\" patchMergeKey:\"type\" protobuf:\"bytes,1,rep,name=conditions\"`
                    \n     // other fields }"
                  properties:
                    lastTransitionTime:
                      description: lastTransitionTime is the last time the condition
                        transitioned from one status to another. This should be when
                        the underlying condition changed.  If that is not known, then
                        using the time when the API field changed is acceptable.
                      format: date-time
                      type: string
                    message:
                      description: message is a human readable message indicating
                        details about the transition. This may be an empty string.
                      maxLength: 32768
                      type: string
                    observedGeneration:
                      description: observedGeneration represents the .metadata.generation
                        that the condition was set based upon. For instance, if .metadata.generation
                        is currently 12, but the .status.conditions[x].observedGeneration
                        is 9, the condition is out of date with respect to the current
                        state of the instance.
                      format: int64
                      minimum: 0
                      type: integer
                    reason:
                      description: reason contains a programmatic identifier indicating
                        the reason for the condition's last transition. Producers
                        of specific condition types may define expected values and
                        meanings for this field, and whether the values are considered
                        a guaranteed API. The value should be a CamelCase string.
                        This field may not be empty.
                      maxLength: 1024
                      minLength: 1
                      pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$
                      type: string
                    status:
                      description: status of the condition, one of True, False, Unknown.
                      enum:
                      - "True"
                      - "False"
                      - Unknown
                      type: string
                    type:
                      description: type of condition in CamelCase or in foo.example.com/CamelCase.
                        --- Many .condition.type values are consistent across resources
                        like Available, but because arbitrary conditions can be useful
                        (see .node.status.conditions), the ability to deconflict is
                        important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
                      maxLength: 316
                      pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$
                      type: string
                  required:
                  - lastTransitionTime
                  - message
                  - reason
                  - status
                  - type
                  type: object
                type: array
              state:
                description: Service state
                type: string
            required:
            - conditions
            - state
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []
